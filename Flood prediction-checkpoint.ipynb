{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flood predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rainfall=pd.read_csv(\"data_temp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTH INDEX</th>\n",
       "      <th>RAINFALL</th>\n",
       "      <th>FLOOD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MONTH INDEX  RAINFALL  FLOOD\n",
       "0            1       0.0      0\n",
       "1            2       6.0      0\n",
       "2            3       0.0      0\n",
       "3            4      12.0      0\n",
       "4            5      19.0      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rainfall.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTH INDEX</th>\n",
       "      <th>RAINFALL</th>\n",
       "      <th>FLOOD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>156.00000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>156.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.50000</td>\n",
       "      <td>107.414744</td>\n",
       "      <td>0.044872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.46317</td>\n",
       "      <td>133.010990</td>\n",
       "      <td>0.207689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.75000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.50000</td>\n",
       "      <td>69.850000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.25000</td>\n",
       "      <td>166.025000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12.00000</td>\n",
       "      <td>995.600000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MONTH INDEX    RAINFALL       FLOOD\n",
       "count    156.00000  156.000000  156.000000\n",
       "mean       6.50000  107.414744    0.044872\n",
       "std        3.46317  133.010990    0.207689\n",
       "min        1.00000    0.000000    0.000000\n",
       "25%        3.75000    3.500000    0.000000\n",
       "50%        6.50000   69.850000    0.000000\n",
       "75%        9.25000  166.025000    0.000000\n",
       "max       12.00000  995.600000    1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rainfall.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTH INDEX</th>\n",
       "      <th>RAINFALL</th>\n",
       "      <th>FLOOD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MONTH INDEX</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.628935</td>\n",
       "      <td>0.309456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAINFALL</th>\n",
       "      <td>0.628935</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.147785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLOOD</th>\n",
       "      <td>0.309456</td>\n",
       "      <td>0.147785</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MONTH INDEX  RAINFALL     FLOOD\n",
       "MONTH INDEX     1.000000  0.628935  0.309456\n",
       "RAINFALL        0.628935  1.000000  0.147785\n",
       "FLOOD           0.309456  0.147785  1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rainfall.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((156, 2), 156)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting all the features within our dataset\n",
    "features = rainfall[['MONTH INDEX', 'RAINFALL']] \n",
    "features = features.to_numpy() # converting feature set to numpy array\n",
    "target = rainfall['FLOOD'].to_numpy() # converting target column to numpy array\n",
    "features.shape, len(target) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##from sklearn.model_selection import train_test_split\n",
    "\n",
    "##featureTrain,featureTest,targetTrain,targetTest= train_test_split(features,target,test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##from sklearn.model_selection import StratifiedShuffleSplit\n",
    "##split=StratifiedShuffleSplit()\n",
    "##for train_index,test_index in split.split(rainfall,rainfall['FLOOD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##from sklearn.linear_model import LogisticRegression\n",
    "##from sklearn.metrics import confusion_matrix\n",
    "##from sklearn.metrics import accuracy_score\n",
    "\n",
    "##model= LogisticRegression()\n",
    "##fittedModel=model.fit(featureTrain,targetTrain)\n",
    "##predictions= fittedModel.predict(featureTest)\n",
    "\n",
    "\n",
    "\n",
    "##print(confusion_matrix(targetTest,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##print(accuracy_score(targetTest,predictions)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input\n",
    "\n",
    "##new_input = [[7,309]]\n",
    "\n",
    "##example=model.predict(new_input)\n",
    "##print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for standardizing data\n",
    "def standardScaler(feature_array):\n",
    "  \n",
    "    total_cols = feature_array.shape[1] # total number of columns \n",
    "    for i in range(total_cols): # iterating through each column\n",
    "        feature_col = feature_array[:, i]\n",
    "        mean = int(feature_col.mean()) # mean stores mean value for the column\n",
    "        std = feature_col.std() # std stores standard deviation value for the column\n",
    "        feature_array[:, i] = (feature_array[:, i] - mean) / std # standard scaling of each element of the column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "standardScaler(features) # performing standardization on our feature set \n",
    "\n",
    "# checking if standardization worked\n",
    "total_cols = features.shape[1] # total number of columns \n",
    "for i in range(total_cols):\n",
    "    print(features[:, i].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating randomized weights for our linear predictor func\n",
    "weights = np.random.rand(2, 2)\n",
    "# creating randomized biases for our linear predictor func\n",
    "biases = np.random.rand(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearPredict(featureMat, weights, biases):\n",
    "    \"\"\"This is the linear predictor function for out MLR model. It calculates the logit scores for each possible outcome.\n",
    "    \n",
    "    Args-\n",
    "        featureMat- A numpy array of features\n",
    "        weights- A numpy array of weights for our model\n",
    "        biases- A numpy array of biases for our model\n",
    "    \n",
    "    Returns-\n",
    "        logitScores- Logit scores for each possible outcome of the target variable for each feature set in the feature matrix\n",
    "    \"\"\"\n",
    "    logitScores = np.array([np.empty([2]) for i in range(featureMat.shape[0])]) # creating empty(garbage value) array for each feature set\n",
    "    \n",
    "    for i in range(featureMat.shape[0]): # iterating through each feature set\n",
    "        logitScores[i] = (weights.dot(featureMat[i].reshape(-1,1)) + biases).reshape(-1) # calculates logit score for each feature set then flattens the logit vector \n",
    "    \n",
    "    return logitScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = rainfall[['MONTH INDEX', 'RAINFALL']]\n",
    "features = features.to_numpy() # converts feature set to numpy array\n",
    "logitTest = linearPredict(features, weights, biases)\n",
    "logitTest.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmaxNormalizer(logitMatrix):\n",
    "    \"\"\"Converts logit scores for each possible outcome to probability values.\n",
    "    \n",
    "    Args-\n",
    "        logitMatrix - This is the output of our logitPredict function; consists  logit scores for each feature set\n",
    "    \n",
    "    Returns-\n",
    "        probabilities - Probability value of each outcome for each feature set\n",
    "    \"\"\"\n",
    "    \n",
    "    probabilities = np.array([np.empty([2]) for i in range(logitMatrix.shape[0])]) # creating empty(garbage value) array for each feature set\n",
    "\n",
    "    for i in range(logitMatrix.shape[0]):\n",
    "        exp = np.exp(logitMatrix[i]) # exponentiates each element of the logit array\n",
    "        sumOfArr = np.sum(exp) # adds up all the values in the exponentiated array\n",
    "        probabilities[i] = exp/sumOfArr # logit scores to probability values\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multinomialLogReg(features, weights, biases):\n",
    "    \"\"\"Performs logistic regression on a given feature set.\n",
    "    \n",
    "    Args- \n",
    "        features- Numpy array of features(standardized)\n",
    "        weights- A numpy array of weights for our model\n",
    "        biases- A numpy array of biases for our model\n",
    "    \n",
    "    Returns-\n",
    "        probabilities, predictions\n",
    "        Here,\n",
    "            probabilities: Probability values for each possible outcome for each feature set in the feature matrix\n",
    "            predictions: Outcome with max probability for each feature set\n",
    "    \"\"\"\n",
    "    logitScores = linearPredict(features, weights, biases)\n",
    "    probabilities = softmaxNormalizer(logitScores)\n",
    "    predictions = np.array([np.argmax(i) for i in probabilities]) #returns the outcome with max probability\n",
    "    return probabilities, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156, 2)\n",
      "[0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 0\n",
      " 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 0 1\n",
      " 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0\n",
      " 0 1 1 1 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0\n",
      " 0 0 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-bbb68c12148f>:14: RuntimeWarning: overflow encountered in exp\n",
      "  exp = np.exp(logitMatrix[i]) # exponentiates each element of the logit array\n",
      "<ipython-input-17-bbb68c12148f>:16: RuntimeWarning: invalid value encountered in true_divide\n",
      "  probabilities[i] = exp/sumOfArr # logit scores to probability values\n"
     ]
    }
   ],
   "source": [
    "probabilities, predictions = multinomialLogReg(features, weights, biases)\n",
    "print(probabilities.shape)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.1025641025641\n"
     ]
    }
   ],
   "source": [
    "def accuracy(predictions, target):\n",
    "    \"\"\"Calculates total accuracy for our model.\n",
    "    \n",
    "    Args- \n",
    "        predictions- Predicted target outcomes as predicted by our MLR function\n",
    "        target- Actual target values\n",
    "    \n",
    "    Returns-\n",
    "        accuracy- Accuracy percentage of our model\n",
    "    \"\"\"\n",
    "    correctPred = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == target[i]:\n",
    "            correctPred += 1\n",
    "    accuracy = correctPred/len(predictions)*100\n",
    "    return accuracy\n",
    "\n",
    "accuracy = accuracy(predictions, target) #calculating accuracy for our model\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((130, 2), (130,), (27, 2), (27,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_test_split(dataframe, test_size = 0.2):\n",
    "    \"\"\"Splits dataset into training and testing sets.\n",
    "    \n",
    "    Args- \n",
    "        dataframe- The dataframe object you want to split\n",
    "        test_size- Size of test dataset that you want\n",
    "    \n",
    "    Returns-\n",
    "        train_features, train_target, test_features, test_target \n",
    "    \"\"\"\n",
    "    \n",
    "    data = dataframe.to_numpy() # converts dataframe to numpy array\n",
    "    totalRows = data.shape[0] # total rows in the dataset\n",
    "    testRows = np.round(totalRows * test_size) # total rows in testing dataset\n",
    "    randRowNum = np.random.randint(0, int(totalRows), int(testRows)) # randomly generated row numbers\n",
    "    testData = np.array([data[i] for i in randRowNum]) # creates test dataset\n",
    "    data = np.delete(data, randRowNum, axis = 0) # deletes test data rows from main dataset; making it training dataset\n",
    "    train_features = data[:, :-1]\n",
    "    train_target = data[:, -1]\n",
    "    test_features = testData[:, :-1]\n",
    "    test_target = testData[:, -1]\n",
    "    \n",
    "    return train_features, train_target, test_features, test_target    \n",
    "\n",
    "# running train_test_split for our dataset\n",
    "train_features, train_target, test_features, test_target = train_test_split(rainfall, test_size = 0.17)\n",
    "standardScaler(train_features) # standard scaling training set \n",
    "standardScaler(test_features) # standard scaling testing set\n",
    "train_features.shape, train_target.shape, test_features.shape, test_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossEntropyLoss(probabilities, target):\n",
    "    \"\"\"Calculates cross entropy loss for a set of predictions and actual targets.\n",
    "    \n",
    "    Args-\n",
    "        predictions- Probability predictions, as returned by multinomialLogReg function\n",
    "        target- Actual target values\n",
    "    Returns- \n",
    "        CELoss- Average cross entropy loss\n",
    "    \"\"\"\n",
    "    n_samples = probabilities.shape[0]\n",
    "    CELoss = 0\n",
    "    for sample, i in zip(probabilities, target):\n",
    "        CELoss += -np.log(sample[i])\n",
    "    CELoss /= n_samples\n",
    "    return CELoss   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochGradDes(learning_rate, epochs, target, features, weights, biases):\n",
    "    \"\"\"Performs stochastic gradient descent optimization on the model.\n",
    "    \n",
    "    Args-\n",
    "        learning_rate- Size of the step the function will take during optimization\n",
    "        epochs- No. of iterations the function will run for on the model\n",
    "        target- Numpy array containing actual target values\n",
    "        features- Numpy array of independent variables\n",
    "        weights- Numpy array containing weights associated with each feature\n",
    "        biases- Array containinig model biases\n",
    "    \n",
    "    Returns-\n",
    "        weights, biases, loss_list\n",
    "        where,\n",
    "            weights- Latest weight calculated (Numpy array)\n",
    "            bias- Latest bias calculated (Numpy array)\n",
    "            loss_list- Array containing list of losses observed after each epoch    \n",
    "    \"\"\"\n",
    "    target = target.astype(int)\n",
    "    loss_list = np.array([]) #initiating an empty array\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        probabilities, _ = multinomialLogReg(features, weights, biases) # Calculates probabilities for each possible outcome\n",
    "        \n",
    "        CELoss = crossEntropyLoss(probabilities, target) # Calculates cross entropy loss for actual target and predictions\n",
    "        loss_list = np.append(loss_list, CELoss) # Adds the CELoss value for the epoch to loss_list\n",
    "        \n",
    "        probabilities[np.arange(features.shape[0]),target] -= 1 # Substract 1 from the scores of the correct outcome\n",
    "        \n",
    "        grad_weight = probabilities.T.dot(features) # gradient of loss w.r.t. weights\n",
    "        grad_biases = np.sum(probabilities, axis = 0).reshape(-1,1) # gradient of loss w.r.t. biases\n",
    "        \n",
    "        #updating weights and biases\n",
    "        weights -= (learning_rate * grad_weight)\n",
    "        biases -= (learning_rate * grad_biases)\n",
    "        \n",
    "    return weights, biases, loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "updatedWeights, updatedBiases, loss_list = stochGradDes(0.1, 2000, train_target, train_features, weights, biases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on test dataset - 92.5925925925926\n"
     ]
    }
   ],
   "source": [
    "testProbabilities, testPredictions = multinomialLogReg(test_features, weights, biases)\n",
    "\n",
    "correctPreds = 0\n",
    "for i in range(len(testPredictions)):\n",
    "    if testPredictions[i] == test_target[i]:\n",
    "        correctPreds += 1\n",
    "acc = correctPreds / len(testPredictions) * 100\n",
    "print(\"Model accuracy on test dataset - {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
